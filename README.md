
# üöÄ Processos de Redund√¢ncia de Arquivos na Azure com API P√∫blica (IBGE - IPCA)

## üéØ Objetivo
Este projeto tem como objetivo demonstrar a cria√ß√£o de um processo de c√≥pia de arquivo utilizando servi√ßos na Azure. Atrav√©s do **Azure Data Factory**, conectamos uma API p√∫blica do IBGE, extra√≠mos dados do **IPCA (√çndice de Pre√ßos ao Consumidor Amplo)** e armazenamos os dados em um **Blob Storage** no formato **JSON**.

---

## üîó Fonte dos Dados
- API P√∫blica do IBGE ‚Äî IPCA (Varia√ß√£o Mensal)  
‚Üí [Documenta√ß√£o IBGE API](https://servicodados.ibge.gov.br/api/docs/agregados)  
‚Üí Endpoint utilizado:  
`https://servicodados.ibge.gov.br/api/v3/agregados/1737/periodos/202305-202404/variaveis/63?localidades=N1[all]`

---

## üèóÔ∏è Arquitetura da Solu√ß√£o
- **Azure Data Factory**
  - Linked Service REST (Conex√£o com API IBGE)
  - Linked Service Blob Storage (Armazenamento)
  - Dataset Origem (API - JSON)
  - Dataset Destino (Blob Storage - JSON)
  - Pipeline de c√≥pia de dados

---

## üîß Etapas do Processo

### 1Ô∏è‚É£ Cria√ß√£o do Linked Service REST (API IBGE)
Configura√ß√£o da conex√£o REST com a API p√∫blica do IBGE para acesso aos dados do IPCA.

![Imagem - Linked Service REST](INSIRA_LINK_DA_IMAGEM_AQUI)

---

### 2Ô∏è‚É£ Cria√ß√£o do Dataset de Origem (API IBGE)
Configura√ß√£o do Dataset de origem utilizando o endpoint da API e o Linked Service REST.

![Imagem - Dataset de Origem](INSIRA_LINK_DA_IMAGEM_AQUI)

---

### 3Ô∏è‚É£ Cria√ß√£o do Linked Service Blob Storage
Configura√ß√£o da conex√£o com o Blob Storage da Azure para armazenamento dos dados extra√≠dos.

![Imagem - Linked Service Blob](INSIRA_LINK_DA_IMAGEM_AQUI)

---

### 4Ô∏è‚É£ Cria√ß√£o do Dataset de Destino (Blob Storage)
Configura√ß√£o do Dataset de destino para receber os dados em formato JSON no Blob Storage.

![Imagem - Dataset de Destino](INSIRA_LINK_DA_IMAGEM_AQUI)

---

### 5Ô∏è‚É£ Cria√ß√£o e Execu√ß√£o do Pipeline (Copy Data)
Desenvolvimento do pipeline com a atividade de **Copy Data**, conex√£o entre o Dataset de origem (API) e o Dataset de destino (Blob Storage).

![Imagem - Pipeline](INSIRA_LINK_DA_IMAGEM_AQUI)

---

## üì¶ Resultado
O arquivo JSON gerado cont√©m os dados de varia√ß√£o mensal do IPCA nos √∫ltimos 12 meses, conforme exemplo abaixo:

```json
{
  "id": "63",
  "variavel": "IPCA - Varia√ß√£o mensal",
  "unidade": "%",
  "resultados": [
    {
      "series": [
        {
          "localidade": {
            "id": "1",
            "nivel": {
              "id": "N1",
              "nome": "Brasil"
            },
            "nome": "Brasil"
          },
          "serie": {
            "202305": "0.23",
            "202306": "-0.08",
            "202307": "0.12",
            "202308": "0.23",
            "202309": "0.26",
            "202310": "0.24",
            "202311": "0.28",
            "202312": "0.56",
            "202401": "0.42",
            "202402": "0.83",
            "202403": "0.16",
            "202404": "0.38"
          }
        }
      ]
    }
  ]
}
```

---

## üèÜ O que foi aprendido
- Como criar pipelines no Azure Data Factory.
- Conectar APIs p√∫blicas via REST no Data Factory.
- Armazenar dados no Azure Blob Storage.
- Princ√≠pios de processos de redund√¢ncia de dados na nuvem.
- Manipula√ß√£o de dados em formato JSON.

---

## üöÄ Pr√≥ximos passos (opcional)
- Transformar o JSON em formato tabular no Power BI, Python ou Azure Data Flow.
- Automatizar a execu√ß√£o desse pipeline periodicamente.

---

## ‚úçÔ∏è Autor
- **Astri [Seu Sobrenome]**  
Analista de Dados | Business Intelligence | Especialista em Processos  

[LinkedIn](https://www.linkedin.com/) | [Portf√≥lio](#) (se tiver)

---
